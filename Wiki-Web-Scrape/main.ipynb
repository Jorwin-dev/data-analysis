{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web Scraping From Wikipedia Using Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essential project to understand web scraping as a whole. The goal is to scrape data from the Wikipedia home page and parse it through various  web scraping techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various web scraping techniques, python modules for web scraping, and processes of Data extraction/processing will be tackled through this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding The Essentials**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Web Scraping:** It is a technique/process in which large amounts of data from a large number of websites is passed through a web scraping software coded in a programming language of choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the structured data is extracted which can be saved locally in our devices, preferably in Excel sheets, JSON or spreadsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It removes the need to manually copy and paste data from websites, and instead use the a scraper to perform that task in a few seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the Overall Purpose:** To help programmers write clear, logical code for small and large scale projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essential Frameworks** in Python, as it is the best for web scraping are *Scrapy* and *Beautiful Soup* as they simplify the processes, making Python easy to use for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essential Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries used for Web Scraping in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Requests (HTTP for Humans) Library for Web Scraping** - Used for making various types of HTTP requests like GET. POST, etc. It's the most basic yet **most essential** of all libraries.\n",
    "- **lxml Library for Web Scraping** - The lmxl library provides super-fast and high-performance parsing of HTML and XML content from websites. It is the **best** library to use for scraping **large datasets**.\n",
    "- **Beautiful Soup Library for Web Scraping** - The work of this library involves creating a **Parse Tree** for parsing content. The most beginner friendly library as it is very easy to work with. \n",
    "- **Selenium Library for Web Scraping** - Originally made for automated testing of web applications, this library overcomes the issue all the aforementioned libraries face i.e. scraping content from dynamically populated websites. This makes it slower and not suitable for industry level projects.\n",
    "- **Scrapy for Web Scraping** - The **boss** of all libraries. It's an entire web scraping framework that is asynchronous in its usage, increasing efficiency, making it very fast. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
